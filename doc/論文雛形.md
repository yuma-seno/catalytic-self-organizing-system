# 階層的反応場を有する触媒的自己組織化システム (CSOS) による省メモリかつ汎用的なエッジAIアーキテクチャ

**Memory-Efficient and General-Purpose Edge AI Architecture based on Catalytic Self-Organizing System (CSOS) with Hierarchical Reaction Fields**

**著者 (Author):**
* **妹尾 悠真 (Yuma Senoo)** - 個人研究者 (Independent Researcher)

---

## Abstract (Summary)
Deploying deep learning models on edge devices with severely limited memory resources, such as microcontrollers (MCUs), remains a significant challenge. Conventional models such as CNNs and Transformers require large input buffers to capture temporal context, which consumes valuable on-chip SRAM. To address this issue, we propose the "Catalytic Self-Organizing System (CSOS)", a novel architecture inspired by biochemical reaction dynamics. CSOS encodes temporal and contextual information into a compact, fixed-size concentration vector, thereby eliminating the need for explicit input buffering. We evaluate CSOS on three heterogeneous tasks: image classification (MNIST), control (CartPole), and wake-word detection. Experimental results show that CSOS achieves strong performance on all three tasks while maintaining an extremely small memory footprint (e.g., a 128-dimensional state vector). Furthermore, an internal analysis reveals a mechanism of "Active Suppression", in which the model dynamically rejects non-target patterns, providing robustness without complex post-processing.

**Keywords:**
memory efficiency, edge AI, artificial chemistry, dynamical systems, wake-word detection, buffer-less architecture

---

## 1. まえがき
IoTデバイスやマイクロコントローラ（MCU）の普及に伴い，数KB〜数MB程度の極めて限られたメモリ資源しか持たない環境でのAI推論（TinyML）への需要が高まっている．しかし，現在主流の深層学習モデルは，メモリ効率の観点で課題を抱えている．例えば，CNNやTransformer [Vaswani 17] で時系列データを処理する場合，一定期間の入力を保持するためのバッファ（スライディングウィンドウ）が必要となり，これがSRAMを圧迫する要因となる．

これに対し，生物の細胞内シグナル伝達系は，過去の履歴を「物質の濃度分布」というコンパクトな内部状態として要約・集約して保持しており，明示的な入力バッファを持たない．この特性は，メモリ制約の厳しいエッジAIにとって理想的である．
本研究では，この生物的特性を模倣したアーキテクチャ「触媒的自己組織化システム (CSOS: Catalytic Self-Organizing System)」を提案する．CSOSは，過去の文脈を固定長の濃度ベクトルに自己組織化させることで，**バッファレス（Buffer-less）** な推論を実現可能とする．

本稿では，画像認識，動的制御，音声認識の3つのタスクにおいて，CSOSがタスクを十分な精度で解きつつ，省メモリ化を実現できることを示す．

## 2. 提案手法

### 2.1 触媒的自己組織化システム (CSOS)
CSOSは，濃度ベクトル $\mathbf{x} \in \mathbb{R}_{\ge 0}^N$ を状態として持つ非線形力学系である [Suzuki 09]．その核心は，情報を「静的なパターン」ではなく「動的な反応プロセス」として保持する点にある．

1.  **注入 (Injection):** 外部入力 $\mathbf{u}_t$ はエンコーダにより反応場へ注入される．
2.  **混合と減衰 (Mixing & Decay):** 過去の状態 $\mathbf{x}_{t-1}$ は減衰しつつ，新たな入力と混合される．
    $$\tilde{\mathbf{x}} = (1 - \lambda)\mathbf{x}_{t-1} + W_{in}(\mathbf{u}_t)$$
3.  **反応 (Reaction):** 触媒テンソル $\mathcal{W}$ による相互作用により，文脈の非線形変換が行われる．
    $$\mathbf{r} = \mathcal{W} \times_1 \tilde{\mathbf{x}} \times_2 \tilde{\mathbf{x}}$$
4.  **更新 (Update):** 反応生成物により状態が更新される．
    $$\mathbf{x}_t = \phi(\tilde{\mathbf{x}} + \alpha \cdot \mathbf{r})$$

ここで $\phi(\cdot)$ は非線形活性化と非負制約，および必要に応じた正規化を施す写像であり，状態ベクトルを「濃度」として解釈可能な範囲に保つ役割を持つ．

### 2.2 省メモリ性 (Memory Efficiency)
CSOSの最大の特徴は，そのメモリ消費量が入力データの長さ（時間長や画素数）に依存せず，**基底数 $N$ のみに依存する**点である．
例えば，1秒間の音声（16kHz）を処理する場合，従来手法では数千サンプルのバッファが必要だが，CSOSでは $N=128$ 程度の状態ベクトル（約512バイト）を更新し続けるだけでよい．これにより，RAM容量が極小のMCU上でも複雑な時系列処理が可能となる．

## 3. 実験と結果

CSOSの汎用性と省メモリ性を検証するため，性質の異なる以下の3つの実験を行った．

### 3.1 実験1：画像分類 (MNIST) - 高圧縮表現
* **設定:** $28 \times 28$ 画素の入力を，わずか $N=64$ の反応場に入力し，分類を行った．
* **結果:** 正答率 98% 以上を達成した．通常，784次元の情報を64次元に圧縮すると情報損失が激しいが，CSOSは反応場のダイナミクスを用いて特徴を復元・補完しており，極小の内部状態でも十分な表現力を持つことが確認された．

### 3.2 実験2：強化学習 (CartPole) - 低次元制御
* **設定:** 倒立振子（CartPole-v1）の制御ポリシーを，基底数 $N=32$ のCSOSで学習させた（進化戦略を使用）．
* **結果:** 30世代程度で最高スコア（500ステップ維持）に到達し，安定した制御を獲得した．
* **省メモリ効果:** 制御に必要なメモリは状態ベクトル（32 float）のみであり，過去の観測履歴（Frame Stacking等）を一切保持せずに，速度や角速度の微分成分を内部ダイナミクスとして表現できていることが示唆された．

### 3.3 実験3：音声コマンド検出 (Wake Word) - バッファレス認識
* **設定:** "System Start" の検出タスクにおいて，時系列バッファを持たず，瞬間のスペクトル入力（短時間のメルスペクトル特徴）を与え続けることを想定した．実装では音声ごとに特徴を抽出しているが，モデル構造自体は逐次入力への拡張を前提としている．
* **結果:** 表1に示す通り，ターゲットに対し高い確信度を示す一方，類似語句に対しては一貫して低い確信度を出力し，棄却した．

**表1 音声コマンド検出結果**

| Input Command | Probability | Result |
| :--- | :--- | :--- |
| **System Start** (Target) | **0.9526** | **Detected** |
| Music Start | 0.0431 | Rejected |
| System Stop | 0.0432 | Rejected |

この結果は，CSOSが「System」という過去の情報を外部メモリなしに内部濃度として保持し，「Start」が来た瞬間に反応できる可能性を示唆している．

## 4. 考察

### 4.1 メモリ効率の比較
本実験で用いられたモデルサイズ（パラメータ数および実行時メモリ）は，同等のタスクをこなすCNNやRNNと比較して極めて小さい．特に実行時メモリ（Activation Memory）においては，設計上，入力長 $T$ に依存しない $O(1)$ の空間計算量を達成しうることが特徴であり，これはエッジAIにおいて決定的な利点となる．

一方で，CSOSは状態表現を強く圧縮するため，Transformer のような大規模モデルと比べて，長期にわたる精緻な文脈依存関係を保持することは難しい．したがって，本手法は「高精度な長期記憶」よりも「省メモリかつ簡潔な文脈要約」を優先するアーキテクチャとして位置付けられる．

### 4.2 ロバスト性と能動的抑制
内部反応の解析により，CSOSは非ターゲット入力（Music Start等）に対して，正解データよりも高い反応エネルギーを消費して抑制していることが判明した（Reaction Power: 正解 $\approx 1.20$ vs 不正解 $\approx 1.48$）．
これは，限られたメモリ容量の中で誤検知を防ぐために，モデルが**「能動的抑制 (Active Suppression)」**というメカニズムを獲得している可能性があると解釈できる．この特性により，リソースの限られた環境下でも高いノイズ耐性を発揮する．

### 4.3 バッファ型モデルとの理論比較
特に音声コマンド検出タスクにおいて，従来の CNN や Transformer ベースのモデルは，過去 $T$ フレーム分の特徴量を保持するスライディングウィンドウ型の入力バッファを前提とすることが多い．メルスペクトログラムの次元数を $D$，フレーム数を $T$，1要素あたりのバイト数を $b$ とすると，単純化した入力バッファのメモリ量 $M_{\text{buffer}}$ は
$$
M_{\text{buffer}} \approx b \cdot D \cdot T
$$
と表される．例えば，$D=64$（メル周波数軸），$T=100$（約1秒相当のフレーム数），$b=4$ byte（32bit float）とすると，入力バッファだけで $M_{\text{buffer}} \approx 25.6$ KB を要する．さらに畳み込み層や自己注意層の中間特徴マップを含めると，実際の一時メモリはこれより増大する．

一方，CSOS では時刻 $t$ における内部状態は濃度ベクトル $\mathbf{x}_t \in \mathbb{R}_{\ge 0}^N$ のみであり，必要な状態メモリ $M_{\text{CSOS}}$ は
$$
M_{\text{CSOS}} \approx b \cdot N
$$
と評価できる．例えば $N=128$ とすると，$M_{\text{CSOS}} \approx 512$ byte となり，上記の単純なバッファ型モデルと比較して理論上 50 倍程度小さい．重要なのは，$M_{\text{buffer}}$ が $T$ に対して線形に増加するのに対し，$M_{\text{CSOS}}$ は入力長 $T$ に依存せず一定である（$O(T)$ vs. $O(1)$）というスケーリングの違いである．

なお，RNN や GRU のような再帰型ニューラルネットワークも，隠れ状態の次元数にのみ依存する固定長の内部状態を持つという点で，CSOS と同様に $O(1)$ のメモリスケーリングを有する．したがって，CSOS の省メモリ性は「RNN/GRU と同じクラスに属しつつ，化学反応ダイナミクスに基づく別種の表現を提供するアーキテクチャ」として位置付けられる．一方で，CNN や Transformer など，入力バッファや長大な系列を前提とするモデルと比較すると，CSOS 型アーキテクチャはバッファ不要・固定長状態という点で，メモリ制約の厳しい環境において有意な選択肢となり得る．

表2に，Wake Word 設定を想定した単純な 1D-CNN モデルと CSOS モデルのメモリ規模の比較例を示す．ここでは，メル次元 $D=64$，フレーム数 $T=100$，チャネル数 $C=32$，内部状態次元 $N=128$ とし，重みパラメータは無視してアクティベーションおよびバッファの概算のみを示す．

**表2 仮想モデルにおけるメモリ規模の一例（32bit float, 概算）**

| モデル | 主な内部表現 | 概算メモリ量 | 備考 |
| :--- | :--- | :---: | :--- |
| 1D-CNN (単純モデル) | 入力バッファ $D\times T$ | 約 25.6 KB | $4\,\text{byte} \cdot 64 \cdot 100$ |
|  | 中間特徴マップ $D\times T\times C$ | 約 0.8 MB | $4\,\text{byte} \cdot 64 \cdot 100 \cdot 32$ |
| CSOS (本研究) | 濃度ベクトル $N$ | 約 0.5 KB | $4\,\text{byte} \cdot 128$ |

このように，ごく単純な設定であっても，バッファおよび中間特徴マップを明示的に保持する CNN 型と，比較的少数の状態成分のみを保持する CSOS 型のあいだには，数十〜数千倍規模のメモリ差が生じうることが分かる．実際の実装ではカーネル数や層数，量子化などによって数値は変動するものの，$O(T)$ vs. $O(1)$ というスケーリングの違いが，長い系列を扱うタスクほど支配的になる点は変わらない．

### 4.4 実測メモリ使用量
提案手法の実行時メモリ消費が極端に不利でないことを確認するため，開発環境（Debian GNU/Linux 13, Python 3.12, CPU版 PyTorch）上で，各 CSOS 実験スクリプトを単独で実行し，/proc ファイルシステムを用いてプロセスの最大常駐メモリ（Max RSS）を測定した．結果を表3に示す．

**表3 CSOS 実験時の最大常駐メモリ使用量（Max RSS）**

| Task | Script | Max RSS [MB] |
| :--- | :--- | :---: |
| 画像分類 (MNIST, CSOS) | src/main_mnist.py | 約 719 |
| 強化学習 (CartPole, CSOS) | src/main_cartpole.py | 約 528 |
| 音声コマンド検出 (CSOS) | src/main_ear.py | 約 985 |
| おもちゃ言語モデル (ChemicalLLM) | src/main_toys_llm.py | 約 621 |

同条件で実装した MLP や RNN ベースラインに対しても，Max RSS はいずれも 500〜1000 MB 程度であり，差は数十 MB 程度にとどまった．これは，本環境では Python ランタイムや PyTorch，librosa 等のライブラリが大きなメモリを占めており，モデル本体（パラメータおよび内部状態）が占める割合が小さいためである．したがって，PC 上の Max RSS 計測だけから CSOS の省メモリ優位性を定量化することは難しいが，少なくとも「CSOS を用いることで極端に不利なメモリ消費になっているわけではない」ことは確認できる．一方で，CSOS における学習パラメータおよび内部状態のサイズ（例えば $N=64$ であれば 64 次元ベクトル）はこれらに比べて極めて小さく，また状態サイズが入力長 $T$ に依存しないことから，適切な実装・圧縮を行うことで，組み込み環境においても小さなメモリフットプリントで動作しうることが期待される．

## 5. むすび
本研究では，生物学的着想に基づく省メモリAIアーキテクチャ CSOS を提案した．実験の結果，CSOSは画像・制御・音声の各タスクにおいて，バッファレスかつ極小の内部状態で高い性能を発揮した．
本手法は，メモリ資源が厳しく制限されるマイクロコントローラやIoTセンサにおける「組み込みAI」の有力な選択肢となり得る．

## 参考文献
[Vaswani 17] Vaswani, A., et al.: Attention is all you need, *NIPS*, Vol. 30 (2017).  
[Suzuki 09] Suzuki, H. and Dittrich, P.: Artificial Chemistry, *Artificial Life*, Vol. 15, No. 2, pp. 1-3 (2009).

---

## 著者紹介

**妹尾 悠真** (正会員)
笠岡商業高校卒業．現在，個人的な趣味として生物模倣型人工知能，特に人工化学と力学系を用いた学習モデルの研究に従事．人工知能学会員．